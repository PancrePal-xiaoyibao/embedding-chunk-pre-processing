# AI Services Configuration
# AI服务配置文件

version: "1.0"

# 服务配置
services:
  
  # 聊天服务配置
  chat:
    default_provider: "stepfun"
    providers:
      
      # Ollama聊天服务
      ollama:
        base_url: "http://localhost:11434"  # Ollama服务地址
        model_name: "qwen3:1.7b"  # 默认模型
        timeout: 30.0  # 请求超时时间（秒）
        max_retries: 3  # 最大重试次数
        stream: false  # 是否使用流式响应
        enable_web_search: false  # 是否启用联网搜索功能
        options:
          temperature: 0.7  # 生成温度
          top_p: 0.9  # Top-p采样
          top_k: 40  # Top-k采样
      
      # GLM-4.5 聊天服务
      glm4:
        base_url: "https://open.bigmodel.cn/api/paas/v4/"  # GLM API地址
        api_key: "your_glm_api_key_here"  # GLM API密钥
        model_name: "glm-4-plus"  # GLM-4.5模型名称
        timeout: 60.0  # 请求超时时间（秒）
        max_retries: 3  # 最大重试次数
        stream: false  # 是否使用流式响应
        enable_web_search: false  # 是否启用联网搜索功能
        options:
          temperature: 0.7  # 生成温度 (0.01-0.99)
          top_p: 0.9  # Top-p采样 (0.01-0.99)
          max_tokens: 4096  # 最大输出token数
          do_sample: true  # 是否启用采样
      
      # OpenAI 聊天服务
      openai:
        base_url: "https://api.openai.com/v1"  # OpenAI API地址
        api_key: "${OPENAI_API_KEY}"  # OpenAI API密钥
        model_name: "gpt-3.5-turbo"  # OpenAI模型名称
        timeout: 60.0  # 请求超时时间（秒）
        max_retries: 3  # 最大重试次数
        stream: false  # 是否使用流式响应
        enable_web_search: false  # 是否启用联网搜索功能
        options:
          temperature: 0.7  # 生成温度 (0.0-2.0)
          top_p: 1.0  # Top-p采样 (0.0-1.0)
          max_tokens: 4096  # 最大输出token数
          frequency_penalty: 0.0  # 频率惩罚 (-2.0-2.0)
          presence_penalty: 0.0  # 存在惩罚 (-2.0-2.0)
      
      # StepFun 聊天服务 (OpenAI兼容)
      stepfun:
        base_url: "https://api.stepfun.com/v1"  # StepFun API地址
        api_key: "5xedBsOeVOrdiVyybuLX9XWUAkNBF2EjjiV5Sv5ze0b3o3ChNEGvHu6xK1SqFWQqs"  # StepFun API密钥
        model_name: "step-1v-8k"  # StepFun模型名称
        timeout: 60.0  # 请求超时时间（秒）
        max_retries: 3  # 最大重试次数
        stream: false  # 是否使用流式响应
        enable_web_search: false  # 是否启用联网搜索功能
        options:
          temperature: 0.7  # 生成温度 (0.0-2.0)
          top_p: 1.0  # Top-p采样 (0.0-1.0)
          max_tokens: 4096  # 最大输出token数
          frequency_penalty: 0.0  # 频率惩罚 (-2.0-2.0)
          presence_penalty: 0.0  # 存在惩罚 (-2.0-2.0)
      
      # DeepSeek 聊天服务 (OpenAI兼容)
      deepseek:
        base_url: "https://api.deepseek.com/v1"  # DeepSeek API地址
        api_key: "${DEEPSEEK_API_KEY}"  # DeepSeek API密钥
        model_name: "deepseek-chat"  # DeepSeek模型名称
        timeout: 60.0  # 请求超时时间（秒）
        max_retries: 3  # 最大重试次数
        stream: false  # 是否使用流式响应
        options:
          temperature: 0.7  # 生成温度 (0.0-2.0)
          top_p: 1.0  # Top-p采样 (0.0-1.0)
          max_tokens: 4096  # 最大输出token数
          frequency_penalty: 0.0  # 频率惩罚 (-2.0-2.0)
          presence_penalty: 0.0  # 存在惩罚 (-2.0-2.0)
  
  # 嵌入服务配置
  embedding:
    default_provider: "ollama"
    providers:
      
      # Ollama嵌入服务
      ollama:
        base_url: "http://localhost:11434"  # Ollama服务地址
        model_name: "nomic-embed-text"  # 嵌入模型
        timeout: 30.0  # 请求超时时间（秒）
        max_retries: 3  # 最大重试次数
      
      # GLM-4.5 嵌入服务
      glm4:
        base_url: "https://open.bigmodel.cn/api/paas/v4/"  # GLM API地址
        api_key: "your_glm_api_key_here"  # GLM API密钥
        model_name: "embedding-2"  # GLM嵌入模型
        timeout: 60.0  # 请求超时时间（秒）
        max_retries: 3  # 最大重试次数
        batch_size: 100  # 批处理大小
      
      # OpenAI 嵌入服务
      openai:
        base_url: "https://api.openai.com/v1"  # OpenAI API地址
        api_key: "${OPENAI_API_KEY}"  # OpenAI API密钥
        model_name: "text-embedding-ada-002"  # OpenAI嵌入模型
        timeout: 60.0  # 请求超时时间（秒）
        max_retries: 3  # 最大重试次数
        batch_size: 100  # 批处理大小
      
      # StepFun 嵌入服务 (OpenAI兼容)
      stepfun:
        base_url: "https://api.stepfun.com/v1"  # StepFun API地址
        api_key: "${STEPFUN_API_KEY}"  # StepFun API密钥
        model_name: "step-1v-embedding"  # StepFun嵌入模型
        timeout: 60.0  # 请求超时时间（秒）
        max_retries: 3  # 最大重试次数
        batch_size: 100  # 批处理大小
      
      # 本地嵌入服务
      local:
        model_name: "all-MiniLM-L6-v2"  # 本地模型名称
        device: "cpu"  # 计算设备 (cpu/cuda)
  
  # 重排序服务配置
  rerank:
    default_provider: "embedding_based"
    providers:
      
      # 基于嵌入的重排序
      embedding_based:
        similarity_method: "cosine"  # 相似度计算方法
        normalize_scores: true  # 是否标准化分数
      
      # Ollama重排序服务
      ollama:
        base_url: "http://localhost:11434"  # Ollama服务地址
        model_name: "qwen3:1.7b"  # 重排序模型
        timeout: 30.0  # 请求超时时间（秒）
        max_retries: 3  # 最大重试次数
      
      # GLM-4.5 重排序服务
      glm4:
        base_url: "https://open.bigmodel.cn/api/paas/v4/"  # GLM API地址
        api_key: "your_glm_api_key_here"  # GLM API密钥
        model_name: "glm-4-plus"  # GLM-4.5模型名称
        timeout: 60.0  # 请求超时时间（秒）
        max_retries: 3  # 最大重试次数
        batch_size: 10  # 批处理大小
      
      # OpenAI 重排序服务 (通过聊天模型实现)
      openai:
        base_url: "https://api.openai.com/v1"  # OpenAI API地址
        api_key: "${OPENAI_API_KEY}"  # OpenAI API密钥
        model_name: "gpt-3.5-turbo"  # OpenAI模型名称
        timeout: 60.0  # 请求超时时间（秒）
        max_retries: 3  # 最大重试次数
        batch_size: 10  # 批处理大小
      
      # StepFun 重排序服务 (OpenAI兼容)
      stepfun:
        base_url: "https://api.stepfun.com/v1"  # StepFun API地址
        api_key: "${STEPFUN_API_KEY}"  # StepFun API密钥
        model_name: "step-1v-8k"  # StepFun模型名称
        timeout: 60.0  # 请求超时时间（秒）
        max_retries: 3  # 最大重试次数
        batch_size: 10  # 批处理大小
      
      # 交叉编码器重排序
      cross_encoder:
        model_name: "cross-encoder/ms-marco-MiniLM-L-6-v2"  # 交叉编码器模型
        device: "cpu"  # 计算设备
        batch_size: 32  # 批处理大小

# 日志配置
logging:
  level: "INFO"  # 日志级别 (DEBUG/INFO/WARNING/ERROR)
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"  # 日志格式
  file: None  # 日志文件路径 (null表示输出到控制台)
