#!/usr/bin/env python3
"""
AI Services é…ç½®ç®¡ç†ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ä¸åŒçš„é…ç½®æ–¹å¼æ¥åˆ›å»ºå’Œç®¡ç†AIæœåŠ¡ã€‚
"""

import os
import sys
import tempfile
from pathlib import Path

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from ai_services import AIServiceFactory
from ai_services.config import (
    get_default_config, 
    create_config_template, 
    validate_config,
    load_config_from_env,
    merge_configs
)


def default_config_example():
    """é»˜è®¤é…ç½®ç¤ºä¾‹"""
    print("=== é»˜è®¤é…ç½®ç¤ºä¾‹ ===")
    
    # è·å–é»˜è®¤é…ç½®
    config = get_default_config()
    print("é»˜è®¤é…ç½®ç»“æ„:")
    print(f"  ç‰ˆæœ¬: {config['version']}")
    print(f"  æœåŠ¡æ•°é‡: {len(config['services'])}")
    
    for service_name, service_config in config['services'].items():
        providers = list(service_config['providers'].keys())
        default_provider = service_config['default_provider']
        print(f"  {service_name}: é»˜è®¤æä¾›å•†={default_provider}, å¯ç”¨æä¾›å•†={providers}")
    
    # ä½¿ç”¨é»˜è®¤é…ç½®åˆ›å»ºå·¥å‚
    factory = AIServiceFactory.create_default()
    print("\nâœ… ä½¿ç”¨é»˜è®¤é…ç½®åˆ›å»ºå·¥å‚æˆåŠŸ")
    
    return config


def config_template_example():
    """é…ç½®æ¨¡æ¿ç¤ºä¾‹"""
    print("\n=== é…ç½®æ¨¡æ¿ç¤ºä¾‹ ===")
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    with tempfile.TemporaryDirectory() as temp_dir:
        # åˆ›å»ºYAMLé…ç½®æ¨¡æ¿
        yaml_path = os.path.join(temp_dir, "config.yaml")
        create_config_template(yaml_path, format="yaml")
        print(f"âœ… YAMLé…ç½®æ¨¡æ¿å·²åˆ›å»º: {yaml_path}")
        
        # åˆ›å»ºJSONé…ç½®æ¨¡æ¿
        json_path = os.path.join(temp_dir, "config.json")
        create_config_template(json_path, format="json")
        print(f"âœ… JSONé…ç½®æ¨¡æ¿å·²åˆ›å»º: {json_path}")
        
        # æ˜¾ç¤ºYAMLé…ç½®å†…å®¹çš„å‰å‡ è¡Œ
        print("\nYAMLé…ç½®æ¨¡æ¿é¢„è§ˆ:")
        with open(yaml_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()[:15]  # æ˜¾ç¤ºå‰15è¡Œ
            for line in lines:
                print(f"  {line.rstrip()}")
            if len(lines) >= 15:
                print("  ...")
        
        # ä»é…ç½®æ–‡ä»¶åˆ›å»ºå·¥å‚
        try:
            factory = AIServiceFactory.from_config_file(yaml_path)
            print("\nâœ… ä»YAMLé…ç½®æ–‡ä»¶åˆ›å»ºå·¥å‚æˆåŠŸ")
        except Exception as e:
            print(f"\nâŒ ä»é…ç½®æ–‡ä»¶åˆ›å»ºå·¥å‚å¤±è´¥: {e}")


def custom_config_example():
    """è‡ªå®šä¹‰é…ç½®ç¤ºä¾‹"""
    print("\n=== è‡ªå®šä¹‰é…ç½®ç¤ºä¾‹ ===")
    
    # åˆ›å»ºè‡ªå®šä¹‰é…ç½®
    custom_config = {
        "version": "1.0",
        "services": {
            "chat": {
                "default_provider": "ollama",
                "providers": {
                    "ollama": {
                        "base_url": "http://localhost:11434",
                        "model_name": "llama2:7b",  # æŒ‡å®šç‰¹å®šç‰ˆæœ¬
                        "timeout": 60.0,  # å¢åŠ è¶…æ—¶æ—¶é—´
                        "max_retries": 5,  # å¢åŠ é‡è¯•æ¬¡æ•°
                        "options": {
                            "temperature": 0.3,  # é™ä½æ¸©åº¦
                            "top_p": 0.8,
                            "top_k": 30
                        }
                    }
                }
            },
            "embedding": {
                "default_provider": "local",  # ä½¿ç”¨æœ¬åœ°æ¨¡å‹
                "providers": {
                    "local": {
                        "model_name": "all-MiniLM-L6-v2",
                        "device": "cpu"
                    },
                    "ollama": {
                        "base_url": "http://localhost:11434",
                        "model_name": "nomic-embed-text",
                        "timeout": 30.0,
                        "max_retries": 3
                    }
                }
            },
            "rerank": {
                "default_provider": "cross_encoder",  # ä½¿ç”¨äº¤å‰ç¼–ç å™¨
                "providers": {
                    "cross_encoder": {
                        "model_name": "cross-encoder/ms-marco-MiniLM-L-6-v2",
                        "device": "cpu",
                        "batch_size": 16
                    },
                    "embedding_based": {
                        "similarity_method": "cosine",
                        "normalize_scores": True
                    }
                }
            }
        },
        "logging": {
            "level": "DEBUG",  # å¯ç”¨è°ƒè¯•æ—¥å¿—
            "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
        }
    }
    
    print("è‡ªå®šä¹‰é…ç½®ç‰¹ç‚¹:")
    print("  - Chat: ä½¿ç”¨llama2:7bæ¨¡å‹ï¼Œé™ä½æ¸©åº¦å‚æ•°")
    print("  - Embedding: é»˜è®¤ä½¿ç”¨æœ¬åœ°æ¨¡å‹")
    print("  - Rerank: é»˜è®¤ä½¿ç”¨äº¤å‰ç¼–ç å™¨")
    print("  - å¯ç”¨DEBUGæ—¥å¿—çº§åˆ«")
    
    # éªŒè¯é…ç½®
    errors = validate_config(custom_config)
    if errors:
        print(f"\nâŒ é…ç½®éªŒè¯å¤±è´¥:")
        for error in errors:
            print(f"    {error}")
        return
    
    print("\nâœ… é…ç½®éªŒè¯é€šè¿‡")
    
    # ä½¿ç”¨è‡ªå®šä¹‰é…ç½®åˆ›å»ºå·¥å‚
    try:
        factory = AIServiceFactory.from_config(custom_config)
        print("âœ… ä½¿ç”¨è‡ªå®šä¹‰é…ç½®åˆ›å»ºå·¥å‚æˆåŠŸ")
        
        # æµ‹è¯•æœåŠ¡åˆ›å»º
        chat_service = factory.create_service("chat")
        print("âœ… ChatæœåŠ¡åˆ›å»ºæˆåŠŸ")
        
        # æ˜¾ç¤ºå®é™…ä½¿ç”¨çš„æä¾›å•†
        chat_providers = factory.get_available_providers("chat")
        embedding_providers = factory.get_available_providers("embedding")
        rerank_providers = factory.get_available_providers("rerank")
        
        print(f"\nå¯ç”¨æä¾›å•†:")
        print(f"  Chat: {chat_providers}")
        print(f"  Embedding: {embedding_providers}")
        print(f"  Rerank: {rerank_providers}")
        
    except Exception as e:
        print(f"\nâŒ ä½¿ç”¨è‡ªå®šä¹‰é…ç½®å¤±è´¥: {e}")


def env_config_example():
    """ç¯å¢ƒå˜é‡é…ç½®ç¤ºä¾‹"""
    print("\n=== ç¯å¢ƒå˜é‡é…ç½®ç¤ºä¾‹ ===")
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    original_env = {}
    env_vars = {
        "OLLAMA_BASE_URL": "http://localhost:11434",
        "OLLAMA_CHAT_MODEL": "llama2:13b",
        "OLLAMA_EMBEDDING_MODEL": "nomic-embed-text:latest",
        "LOG_LEVEL": "WARNING"
    }
    
    print("è®¾ç½®ç¯å¢ƒå˜é‡:")
    for key, value in env_vars.items():
        original_env[key] = os.environ.get(key)  # ä¿å­˜åŸå€¼
        os.environ[key] = value
        print(f"  {key}={value}")
    
    try:
        # ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®
        env_config = load_config_from_env()
        
        print("\nä»ç¯å¢ƒå˜é‡åŠ è½½çš„é…ç½®:")
        print(f"  Ollama Base URL: {env_config['services']['chat']['providers']['ollama']['base_url']}")
        print(f"  Chat Model: {env_config['services']['chat']['providers']['ollama']['model_name']}")
        print(f"  Embedding Model: {env_config['services']['embedding']['providers']['ollama']['model_name']}")
        print(f"  Log Level: {env_config['logging']['level']}")
        
        # ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®åˆ›å»ºå·¥å‚
        factory = AIServiceFactory.from_config(env_config)
        print("\nâœ… ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®åˆ›å»ºå·¥å‚æˆåŠŸ")
        
    except Exception as e:
        print(f"\nâŒ ç¯å¢ƒå˜é‡é…ç½®å¤±è´¥: {e}")
    
    finally:
        # æ¢å¤åŸå§‹ç¯å¢ƒå˜é‡
        for key, original_value in original_env.items():
            if original_value is None:
                os.environ.pop(key, None)
            else:
                os.environ[key] = original_value


def config_merge_example():
    """é…ç½®åˆå¹¶ç¤ºä¾‹"""
    print("\n=== é…ç½®åˆå¹¶ç¤ºä¾‹ ===")
    
    # åŸºç¡€é…ç½®
    base_config = get_default_config()
    
    # è¦†ç›–é…ç½®
    override_config = {
        "services": {
            "chat": {
                "providers": {
                    "ollama": {
                        "model_name": "codellama",  # æ›´æ”¹æ¨¡å‹
                        "options": {
                            "temperature": 0.1  # æ›´æ”¹æ¸©åº¦
                        }
                    }
                }
            },
            "embedding": {
                "default_provider": "local"  # æ›´æ”¹é»˜è®¤æä¾›å•†
            }
        },
        "logging": {
            "level": "ERROR"  # æ›´æ”¹æ—¥å¿—çº§åˆ«
        }
    }
    
    print("åŸºç¡€é…ç½®:")
    print(f"  Chatæ¨¡å‹: {base_config['services']['chat']['providers']['ollama']['model_name']}")
    print(f"  Chatæ¸©åº¦: {base_config['services']['chat']['providers']['ollama']['options']['temperature']}")
    print(f"  Embeddingé»˜è®¤æä¾›å•†: {base_config['services']['embedding']['default_provider']}")
    print(f"  æ—¥å¿—çº§åˆ«: {base_config['logging']['level']}")
    
    print("\nè¦†ç›–é…ç½®:")
    print(f"  Chatæ¨¡å‹: {override_config['services']['chat']['providers']['ollama']['model_name']}")
    print(f"  Chatæ¸©åº¦: {override_config['services']['chat']['providers']['ollama']['options']['temperature']}")
    print(f"  Embeddingé»˜è®¤æä¾›å•†: {override_config['services']['embedding']['default_provider']}")
    print(f"  æ—¥å¿—çº§åˆ«: {override_config['logging']['level']}")
    
    # åˆå¹¶é…ç½®
    merged_config = merge_configs(base_config, override_config)
    
    print("\nåˆå¹¶åé…ç½®:")
    print(f"  Chatæ¨¡å‹: {merged_config['services']['chat']['providers']['ollama']['model_name']}")
    print(f"  Chatæ¸©åº¦: {merged_config['services']['chat']['providers']['ollama']['options']['temperature']}")
    print(f"  Chat Top-P: {merged_config['services']['chat']['providers']['ollama']['options']['top_p']}")  # ä¿æŒåŸå€¼
    print(f"  Embeddingé»˜è®¤æä¾›å•†: {merged_config['services']['embedding']['default_provider']}")
    print(f"  æ—¥å¿—çº§åˆ«: {merged_config['logging']['level']}")
    
    # éªŒè¯åˆå¹¶åçš„é…ç½®
    errors = validate_config(merged_config)
    if errors:
        print(f"\nâŒ åˆå¹¶é…ç½®éªŒè¯å¤±è´¥:")
        for error in errors:
            print(f"    {error}")
    else:
        print("\nâœ… åˆå¹¶é…ç½®éªŒè¯é€šè¿‡")


def config_validation_example():
    """é…ç½®éªŒè¯ç¤ºä¾‹"""
    print("\n=== é…ç½®éªŒè¯ç¤ºä¾‹ ===")
    
    # æœ‰æ•ˆé…ç½®
    valid_config = get_default_config()
    errors = validate_config(valid_config)
    print(f"æœ‰æ•ˆé…ç½®éªŒè¯ç»“æœ: {len(errors)} ä¸ªé”™è¯¯")
    
    # æ— æ•ˆé…ç½®ç¤ºä¾‹
    invalid_configs = [
        {
            "name": "ç¼ºå°‘versionå­—æ®µ",
            "config": {
                "services": {
                    "chat": {
                        "default_provider": "ollama",
                        "providers": {"ollama": {"base_url": "http://localhost:11434"}}
                    }
                }
            }
        },
        {
            "name": "ç¼ºå°‘serviceså­—æ®µ",
            "config": {
                "version": "1.0"
            }
        },
        {
            "name": "é»˜è®¤æä¾›å•†ä¸å­˜åœ¨",
            "config": {
                "version": "1.0",
                "services": {
                    "chat": {
                        "default_provider": "nonexistent",
                        "providers": {
                            "ollama": {
                                "base_url": "http://localhost:11434",
                                "model_name": "llama2"
                            }
                        }
                    }
                }
            }
        },
        {
            "name": "Ollamaæä¾›å•†ç¼ºå°‘å¿…éœ€å­—æ®µ",
            "config": {
                "version": "1.0",
                "services": {
                    "chat": {
                        "default_provider": "ollama",
                        "providers": {
                            "ollama": {
                                "base_url": "http://localhost:11434"
                                # ç¼ºå°‘ model_name
                            }
                        }
                    }
                }
            }
        }
    ]
    
    print("\næ— æ•ˆé…ç½®éªŒè¯:")
    for example in invalid_configs:
        print(f"\n  {example['name']}:")
        errors = validate_config(example['config'])
        if errors:
            for error in errors:
                print(f"    âŒ {error}")
        else:
            print("    âœ… æ„å¤–é€šè¿‡éªŒè¯")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ AI Services é…ç½®ç®¡ç†ç¤ºä¾‹")
    print("=" * 50)
    
    # å„ç§é…ç½®ç¤ºä¾‹
    default_config_example()
    config_template_example()
    custom_config_example()
    env_config_example()
    config_merge_example()
    config_validation_example()
    
    print("\nğŸ‰ æ‰€æœ‰é…ç½®ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
    print("\nğŸ’¡ æç¤º:")
    print("  - ä½¿ç”¨ create_config_template() ç”Ÿæˆé…ç½®æ¨¡æ¿")
    print("  - ä½¿ç”¨ validate_config() éªŒè¯é…ç½®æœ‰æ•ˆæ€§")
    print("  - æ”¯æŒYAMLå’ŒJSONæ ¼å¼çš„é…ç½®æ–‡ä»¶")
    print("  - å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–é…ç½®")
    print("  - ä½¿ç”¨ merge_configs() åˆå¹¶å¤šä¸ªé…ç½®")


if __name__ == "__main__":
    main()