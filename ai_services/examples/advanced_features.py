#!/usr/bin/env python3
"""
AI Services é«˜çº§åŠŸèƒ½ç¤ºä¾‹

æ¼”ç¤ºAIæœåŠ¡æ¨¡å—çš„é«˜çº§åŠŸèƒ½ï¼ŒåŒ…æ‹¬æ‰¹å¤„ç†ã€å¼‚æ­¥æ“ä½œã€é”™è¯¯å¤„ç†ã€å¥åº·æ£€æŸ¥ç­‰ã€‚
"""

import asyncio
import os
import sys
import time
from typing import List

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from ai_services import AIServiceFactory, create_chat_service, create_embedding_service, create_rerank_service
from ai_services.services.models import create_user_message, create_system_message
from ai_services.core.exceptions import (
    AIServiceError, 
    ServiceNotAvailableError, 
    ConnectionError,
    ModelNotFoundError
)


async def health_check_example():
    """å¥åº·æ£€æŸ¥ç¤ºä¾‹"""
    print("=== å¥åº·æ£€æŸ¥ç¤ºä¾‹ ===")
    
    factory = AIServiceFactory.create_default()
    
    # æ£€æŸ¥æ‰€æœ‰æœåŠ¡çš„å¥åº·çŠ¶æ€
    services = ["chat", "embedding", "rerank"]
    
    for service_name in services:
        print(f"\næ£€æŸ¥ {service_name} æœåŠ¡:")
        try:
            service = factory.create_service(service_name)
            is_healthy = await service.health_check()
            
            if is_healthy:
                print(f"  âœ… {service_name} æœåŠ¡å¥åº·")
            else:
                print(f"  âŒ {service_name} æœåŠ¡ä¸å¥åº·")
                
        except Exception as e:
            print(f"  âŒ {service_name} æœåŠ¡æ£€æŸ¥å¤±è´¥: {e}")
    
    # æµ‹è¯•è¿æ¥
    print(f"\næµ‹è¯•å·¥å‚è¿æ¥:")
    try:
        connection_results = await factory.test_connections()
        for service_name, result in connection_results.items():
            status = "âœ… è¿æ¥æˆåŠŸ" if result else "âŒ è¿æ¥å¤±è´¥"
            print(f"  {service_name}: {status}")
    except Exception as e:
        print(f"  âŒ è¿æ¥æµ‹è¯•å¤±è´¥: {e}")


async def batch_processing_example():
    """æ‰¹å¤„ç†ç¤ºä¾‹"""
    print("\n=== æ‰¹å¤„ç†ç¤ºä¾‹ ===")
    
    # åˆ›å»ºåµŒå…¥æœåŠ¡
    embedding_service = create_embedding_service()
    
    # å‡†å¤‡æ‰¹é‡æ–‡æœ¬
    texts = [
        "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯",
        "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒæŠ€æœ¯",
        "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸ",
        "ç¥ç»ç½‘ç»œæ˜¯æ·±åº¦å­¦ä¹ çš„åŸºç¡€",
        "è‡ªç„¶è¯­è¨€å¤„ç†æ˜¯AIçš„é‡è¦åº”ç”¨",
        "è®¡ç®—æœºè§†è§‰è®©æœºå™¨èƒ½å¤Ÿç†è§£å›¾åƒ",
        "å¼ºåŒ–å­¦ä¹ é€šè¿‡è¯•é”™æ¥å­¦ä¹ æœ€ä¼˜ç­–ç•¥",
        "å¤§è¯­è¨€æ¨¡å‹æ”¹å˜äº†NLPçš„å‘å±•æ–¹å‘"
    ]
    
    print(f"æ‰¹é‡å¤„ç† {len(texts)} ä¸ªæ–‡æœ¬...")
    
    start_time = time.time()
    
    try:
        # æ£€æŸ¥æœåŠ¡æ˜¯å¦æ”¯æŒæ‰¹é‡å¤„ç†
        if hasattr(embedding_service, 'embed_batch'):
            print("ä½¿ç”¨æ‰¹é‡åµŒå…¥æ–¹æ³•...")
            embeddings = await embedding_service.embed_batch(texts)
        else:
            print("ä½¿ç”¨å•ä¸ªåµŒå…¥æ–¹æ³•...")
            embeddings = []
            for text in texts:
                result = await embedding_service.embed(text)
                embeddings.append(result.vectors[0])
        
        end_time = time.time()
        
        print(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆ")
        print(f"  å¤„ç†æ—¶é—´: {end_time - start_time:.2f} ç§’")
        print(f"  å¹³å‡æ¯ä¸ªæ–‡æœ¬: {(end_time - start_time) / len(texts):.3f} ç§’")
        print(f"  åµŒå…¥ç»´åº¦: {len(embeddings[0]) if embeddings else 0}")
        
        # è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦
        if len(embeddings) >= 2:
            from ai_services.services.embedding_service import cosine_similarity
            similarity = cosine_similarity(embeddings[0], embeddings[1])
            print(f"  å‰ä¸¤ä¸ªæ–‡æœ¬ç›¸ä¼¼åº¦: {similarity:.3f}")
            
    except Exception as e:
        print(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {e}")


async def async_concurrent_example():
    """å¼‚æ­¥å¹¶å‘ç¤ºä¾‹"""
    print("\n=== å¼‚æ­¥å¹¶å‘ç¤ºä¾‹ ===")
    
    factory = AIServiceFactory.create_default()
    
    # åˆ›å»ºå¤šä¸ªæœåŠ¡
    chat_service = factory.create_service("chat")
    embedding_service = factory.create_service("embedding")
    rerank_service = factory.create_service("rerank")
    
    # å‡†å¤‡å¹¶å‘ä»»åŠ¡
    async def chat_task():
        """èŠå¤©ä»»åŠ¡"""
        messages = [
            create_system_message("ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"),
            create_user_message("è¯·ç®€å•ä»‹ç»ä¸€ä¸‹æœºå™¨å­¦ä¹ ã€‚")
        ]
        response = await chat_service.chat_async(messages)
        return f"Chat: {response.message.content[:50]}..."
    
    async def embedding_task():
        """åµŒå…¥ä»»åŠ¡"""
        text = "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯"
        response = await embedding_service.embed(text)
        return f"Embedding: ç»´åº¦={len(response.vectors[0])}"
    
    async def rerank_task():
        """é‡æ’åºä»»åŠ¡"""
        query = "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ "
        documents = [
            "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯",
            "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„å­é¢†åŸŸ",
            "ä»Šå¤©å¤©æ°”å¾ˆå¥½"
        ]
        response = await rerank_service.rerank(query, documents)
        return f"Rerank: æœ€ç›¸å…³æ–‡æ¡£å¾—åˆ†={response.results[0].score:.3f}"
    
    print("å¯åŠ¨å¹¶å‘ä»»åŠ¡...")
    start_time = time.time()
    
    try:
        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        results = await asyncio.gather(
            chat_task(),
            embedding_task(),
            rerank_task(),
            return_exceptions=True
        )
        
        end_time = time.time()
        
        print(f"âœ… å¹¶å‘ä»»åŠ¡å®Œæˆ (è€—æ—¶: {end_time - start_time:.2f} ç§’)")
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                print(f"  ä»»åŠ¡ {i+1}: âŒ {result}")
            else:
                print(f"  ä»»åŠ¡ {i+1}: âœ… {result}")
                
    except Exception as e:
        print(f"âŒ å¹¶å‘ä»»åŠ¡å¤±è´¥: {e}")


async def error_handling_example():
    """é”™è¯¯å¤„ç†ç¤ºä¾‹"""
    print("\n=== é”™è¯¯å¤„ç†ç¤ºä¾‹ ===")
    
    # æµ‹è¯•ä¸åŒç±»å‹çš„é”™è¯¯
    error_scenarios = [
        {
            "name": "æœåŠ¡ä¸å¯ç”¨",
            "action": lambda: create_chat_service(provider="nonexistent")
        },
        {
            "name": "è¿æ¥é”™è¯¯",
            "action": lambda: create_chat_service(
                provider="ollama",
                base_url="http://invalid-host:11434"
            )
        },
        {
            "name": "æ¨¡å‹ä¸å­˜åœ¨",
            "action": lambda: create_chat_service(
                provider="ollama",
                model_name="nonexistent-model"
            )
        }
    ]
    
    for scenario in error_scenarios:
        print(f"\næµ‹è¯•: {scenario['name']}")
        try:
            service = scenario['action']()
            
            # å°è¯•ä½¿ç”¨æœåŠ¡
            if hasattr(service, 'health_check'):
                await service.health_check()
            
            print(f"  âš ï¸  æ„å¤–æˆåŠŸ")
            
        except ServiceNotAvailableError as e:
            print(f"  âœ… æ•è·æœåŠ¡ä¸å¯ç”¨é”™è¯¯: {e}")
        except ConnectionError as e:
            print(f"  âœ… æ•è·è¿æ¥é”™è¯¯: {e}")
        except ModelNotFoundError as e:
            print(f"  âœ… æ•è·æ¨¡å‹ä¸å­˜åœ¨é”™è¯¯: {e}")
        except AIServiceError as e:
            print(f"  âœ… æ•è·AIæœåŠ¡é”™è¯¯: {e}")
        except Exception as e:
            print(f"  âŒ æœªé¢„æœŸçš„é”™è¯¯: {type(e).__name__}: {e}")


async def streaming_example():
    """æµå¼å¤„ç†ç¤ºä¾‹"""
    print("\n=== æµå¼å¤„ç†ç¤ºä¾‹ ===")
    
    try:
        chat_service = create_chat_service()
        
        messages = [
            create_system_message("ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"),
            create_user_message("è¯·è¯¦ç»†è§£é‡Šä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼ŒåŒ…æ‹¬å…¶åŸç†å’Œåº”ç”¨ã€‚")
        ]
        
        print("å¼€å§‹æµå¼èŠå¤©...")
        print("å›å¤: ", end="", flush=True)
        
        full_response = ""
        async for chunk in chat_service.chat_stream(messages):
            if chunk.message and chunk.message.content:
                content = chunk.message.content
                print(content, end="", flush=True)
                full_response += content
        
        print(f"\n\nâœ… æµå¼èŠå¤©å®Œæˆ")
        print(f"æ€»å­—ç¬¦æ•°: {len(full_response)}")
        
    except Exception as e:
        print(f"âŒ æµå¼å¤„ç†å¤±è´¥: {e}")


async def model_management_example():
    """æ¨¡å‹ç®¡ç†ç¤ºä¾‹"""
    print("\n=== æ¨¡å‹ç®¡ç†ç¤ºä¾‹ ===")
    
    try:
        # åˆ›å»ºOllamaæœåŠ¡
        chat_service = create_chat_service(provider="ollama")
        
        if hasattr(chat_service, 'list_models'):
            print("è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨...")
            models = await chat_service.list_models()
            
            print(f"âœ… æ‰¾åˆ° {len(models)} ä¸ªæ¨¡å‹:")
            for model in models[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"  - {model}")
            
            if len(models) > 5:
                print(f"  ... è¿˜æœ‰ {len(models) - 5} ä¸ªæ¨¡å‹")
        
        # æµ‹è¯•æ¨¡å‹æ‹‰å–ï¼ˆä»…æ¼”ç¤ºï¼Œä¸å®é™…æ‰§è¡Œï¼‰
        if hasattr(chat_service, 'pull_model'):
            print(f"\næ¨¡å‹æ‹‰å–åŠŸèƒ½å¯ç”¨")
            print(f"  å¯ä»¥ä½¿ç”¨ chat_service.pull_model('model_name') æ‹‰å–æ–°æ¨¡å‹")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹ç®¡ç†å¤±è´¥: {e}")


async def performance_monitoring_example():
    """æ€§èƒ½ç›‘æ§ç¤ºä¾‹"""
    print("\n=== æ€§èƒ½ç›‘æ§ç¤ºä¾‹ ===")
    
    # ç›‘æ§ä¸åŒæ“ä½œçš„æ€§èƒ½
    operations = [
        {
            "name": "Chatå“åº”",
            "action": lambda: create_chat_service().chat_async([
                create_user_message("Hello, how are you?")
            ])
        },
        {
            "name": "æ–‡æœ¬åµŒå…¥",
            "action": lambda: create_embedding_service().embed("Hello world")
        },
        {
            "name": "æ–‡æ¡£é‡æ’åº",
            "action": lambda: create_rerank_service().rerank(
                "machine learning",
                ["AI is the future", "Machine learning is a subset of AI", "Weather is nice"]
            )
        }
    ]
    
    performance_results = []
    
    for operation in operations:
        print(f"\næµ‹è¯•: {operation['name']}")
        
        # æ‰§è¡Œå¤šæ¬¡æµ‹è¯•
        times = []
        success_count = 0
        
        for i in range(3):  # æ‰§è¡Œ3æ¬¡
            try:
                start_time = time.time()
                await operation['action']()
                end_time = time.time()
                
                duration = end_time - start_time
                times.append(duration)
                success_count += 1
                
                print(f"  ç¬¬{i+1}æ¬¡: {duration:.3f}ç§’")
                
            except Exception as e:
                print(f"  ç¬¬{i+1}æ¬¡: âŒ {e}")
        
        if times:
            avg_time = sum(times) / len(times)
            min_time = min(times)
            max_time = max(times)
            
            performance_results.append({
                "operation": operation['name'],
                "avg_time": avg_time,
                "min_time": min_time,
                "max_time": max_time,
                "success_rate": success_count / 3
            })
            
            print(f"  âœ… å¹³å‡è€—æ—¶: {avg_time:.3f}ç§’")
            print(f"  ğŸ“Š èŒƒå›´: {min_time:.3f}s - {max_time:.3f}s")
            print(f"  ğŸ“ˆ æˆåŠŸç‡: {success_count}/3")
    
    # æ€§èƒ½æ€»ç»“
    if performance_results:
        print(f"\nğŸ“Š æ€§èƒ½æ€»ç»“:")
        for result in performance_results:
            print(f"  {result['operation']}: {result['avg_time']:.3f}s (æˆåŠŸç‡: {result['success_rate']:.1%})")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ AI Services é«˜çº§åŠŸèƒ½ç¤ºä¾‹")
    print("=" * 50)
    
    # æ‰§è¡Œå„ç§é«˜çº§åŠŸèƒ½ç¤ºä¾‹
    await health_check_example()
    await batch_processing_example()
    await async_concurrent_example()
    await error_handling_example()
    await streaming_example()
    await model_management_example()
    await performance_monitoring_example()
    
    print("\nğŸ‰ æ‰€æœ‰é«˜çº§åŠŸèƒ½ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
    print("\nğŸ’¡ é«˜çº§åŠŸèƒ½æ€»ç»“:")
    print("  - âœ… å¥åº·æ£€æŸ¥å’Œè¿æ¥æµ‹è¯•")
    print("  - âš¡ æ‰¹å¤„ç†å’Œå¼‚æ­¥å¹¶å‘")
    print("  - ğŸ›¡ï¸  å®Œå–„çš„é”™è¯¯å¤„ç†")
    print("  - ğŸŒŠ æµå¼å¤„ç†æ”¯æŒ")
    print("  - ğŸ”§ æ¨¡å‹ç®¡ç†åŠŸèƒ½")
    print("  - ğŸ“Š æ€§èƒ½ç›‘æ§èƒ½åŠ›")


if __name__ == "__main__":
    asyncio.run(main())