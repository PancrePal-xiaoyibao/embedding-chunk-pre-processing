#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å‘½ä»¤è¡Œç•Œé¢æ¨¡å—

æä¾›å®Œæ•´çš„å‘½ä»¤è¡Œç•Œé¢åŠŸèƒ½ï¼Œæ”¯æŒæ–‡æ¡£å¤„ç†ã€é…ç½®ç®¡ç†ã€è´¨é‡è¯„ä¼°ç­‰æ“ä½œã€‚
åŒ…å«ä¸°å¯Œçš„å‘½ä»¤è¡Œå‚æ•°ã€è¿›åº¦æ˜¾ç¤ºã€ç»“æœè¾“å‡ºç­‰åŠŸèƒ½ã€‚
"""

import os
import sys
import json
import time
import argparse
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import asdict
from datetime import datetime

# å¯¼å…¥é¡¹ç›®æ¨¡å—
try:
    # æ–°çš„srcç›®å½•ç»“æ„å¯¼å…¥
    from core.document_processor import DocumentProcessor, ProcessingResult
    from config.config_manager import ConfigManager
    from core.quality_evaluator import QualityEvaluator, QualityEvaluationResult
    from core.chunk_strategies import BaseChunkingStrategy, ChunkingConfig
except ImportError:
    # å‘åå…¼å®¹çš„å¯¼å…¥
    try:
        from document_processor import DocumentProcessor, ProcessingResult
        from config_manager import ConfigManager
        from quality_evaluator import QualityEvaluator, QualityEvaluationResult
        from chunk_strategies import BaseChunkingStrategy, ChunkingConfig
    except ImportError as e:
        print(f"å¯¼å…¥é”™è¯¯: {e}")
        sys.exit(1)


class CLIInterface:
    """
    å‘½ä»¤è¡Œç•Œé¢ç±»
    
    æä¾›å®Œæ•´çš„å‘½ä»¤è¡Œæ“ä½œåŠŸèƒ½ï¼ŒåŒ…æ‹¬æ–‡æ¡£å¤„ç†ã€é…ç½®ç®¡ç†ã€è´¨é‡è¯„ä¼°ç­‰ã€‚
    """
    
    def __init__(self, config_path: str = "config.json", app=None, config_manager=None, logger=None):
        """
        åˆå§‹åŒ–å‘½ä»¤è¡Œç•Œé¢
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            app: ä¸»åº”ç”¨å®ä¾‹ï¼ˆå¯é€‰ï¼‰
            config_manager: é…ç½®ç®¡ç†å™¨å®ä¾‹ï¼ˆå¯é€‰ï¼‰
            logger: æ—¥å¿—è®°å½•å™¨ï¼ˆå¯é€‰ï¼‰
        """
        self.config_path = config_path
        self.app = app
        
        # ä½¿ç”¨æä¾›çš„config_manageræˆ–åˆ›å»ºæ–°çš„
        if config_manager:
            self.config_manager = config_manager
        else:
            self.config_manager = ConfigManager(config_path)
        
        # ä½¿ç”¨æä¾›çš„loggeræˆ–åˆ›å»ºæ–°çš„
        if logger:
            self.logger = logger
        else:
            self.logger = logging.getLogger(self.__class__.__name__)
        
        # åˆå§‹åŒ–å¤„ç†å™¨
        self.document_processor = DocumentProcessor(self.config_manager)
        self.quality_evaluator = QualityEvaluator(self.config_manager.config)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = Path("outputs")
        self.output_dir.mkdir(exist_ok=True)
    
    def create_parser(self) -> argparse.ArgumentParser:
        """
        åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨
        
        Returns:
            argparse.ArgumentParser: å‚æ•°è§£æå™¨
        """
        parser = argparse.ArgumentParser(
            description="Embeddingå¢å¼ºç³»ç»Ÿ - å‘½ä»¤è¡Œç•Œé¢",
            formatter_class=argparse.RawDescriptionHelpFormatter,
            epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  %(prog)s process document.md                    # å¤„ç†å•ä¸ªæ–‡æ¡£
  %(prog)s process docs/ -r                       # é€’å½’å¤„ç†ç›®å½•
  %(prog)s evaluate document.md                   # è¯„ä¼°æ–‡æ¡£è´¨é‡
  %(prog)s config --show                          # æ˜¾ç¤ºå½“å‰é…ç½®
  %(prog)s config --set chunk_size=1000           # è®¾ç½®é…ç½®é¡¹
  %(prog)s batch files.txt                        # æ‰¹é‡å¤„ç†æ–‡ä»¶åˆ—è¡¨
            """
        )
        
        # å…¨å±€å‚æ•°
        parser.add_argument(
            '--config', '-c',
            default='config.json',
            help='é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config.json)'
        )
        
        parser.add_argument(
            '--output', '-o',
            default='outputs',
            help='è¾“å‡ºç›®å½• (é»˜è®¤: outputs)'
        )
        
        parser.add_argument(
            '--verbose', '-v',
            action='store_true',
            help='è¯¦ç»†è¾“å‡ºæ¨¡å¼'
        )
        
        parser.add_argument(
            '--quiet', '-q',
            action='store_true',
            help='é™é»˜æ¨¡å¼ï¼Œåªè¾“å‡ºé”™è¯¯ä¿¡æ¯'
        )
        
        parser.add_argument(
            '--format',
            choices=['text', 'json', 'csv'],
            default='text',
            help='è¾“å‡ºæ ¼å¼ (é»˜è®¤: text)'
        )
        
        # å­å‘½ä»¤
        subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
        
        # å¤„ç†å‘½ä»¤
        process_parser = subparsers.add_parser(
            'process',
            help='å¤„ç†æ–‡æ¡£',
            description='å¤„ç†Markdownæ–‡æ¡£ï¼Œè¿›è¡Œåˆ†å—å’Œå…³é”®è¯æå–'
        )
        
        process_parser.add_argument(
            'input',
            help='è¾“å…¥æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„'
        )
        
        process_parser.add_argument(
            '--recursive', '-r',
            action='store_true',
            help='é€’å½’å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶'
        )
        
        process_parser.add_argument(
            '--strategy',
            choices=['token', 'semantic', 'structured', 'hybrid'],
            help='åˆ†å—ç­–ç•¥'
        )
        
        process_parser.add_argument(
            '--chunk-size',
            type=int,
            help='ç›®æ ‡åˆ†å—å¤§å°'
        )
        
        process_parser.add_argument(
            '--keywords',
            type=int,
            help='æ¯ä¸ªåˆ†å—çš„æœ€å¤§å…³é”®è¯æ•°'
        )
        
        process_parser.add_argument(
            '--no-evaluation',
            action='store_true',
            help='è·³è¿‡è´¨é‡è¯„ä¼°'
        )
        
        process_parser.add_argument(
            '--save-intermediate',
            action='store_true',
            help='ä¿å­˜ä¸­é—´å¤„ç†ç»“æœ'
        )
        
        # è¯„ä¼°å‘½ä»¤
        evaluate_parser = subparsers.add_parser(
            'evaluate',
            help='è¯„ä¼°æ–‡æ¡£è´¨é‡',
            description='è¯„ä¼°æ–‡æ¡£åˆ†å—è´¨é‡å¹¶æä¾›ä¼˜åŒ–å»ºè®®'
        )
        
        evaluate_parser.add_argument(
            'input',
            help='è¾“å…¥æ–‡ä»¶è·¯å¾„'
        )
        
        evaluate_parser.add_argument(
            '--detailed',
            action='store_true',
            help='æ˜¾ç¤ºè¯¦ç»†è¯„ä¼°ç»“æœ'
        )
        
        evaluate_parser.add_argument(
            '--export',
            help='å¯¼å‡ºè¯„ä¼°ç»“æœåˆ°æ–‡ä»¶'
        )
        
        # é…ç½®å‘½ä»¤
        config_parser = subparsers.add_parser(
            'config',
            help='é…ç½®ç®¡ç†',
            description='ç®¡ç†ç³»ç»Ÿé…ç½®å‚æ•°'
        )
        
        config_group = config_parser.add_mutually_exclusive_group(required=True)
        
        config_group.add_argument(
            '--show',
            action='store_true',
            help='æ˜¾ç¤ºå½“å‰é…ç½®'
        )
        
        config_group.add_argument(
            '--set',
            action='append',
            metavar='KEY=VALUE',
            help='è®¾ç½®é…ç½®é¡¹ (å¯å¤šæ¬¡ä½¿ç”¨)'
        )
        
        config_group.add_argument(
            '--reset',
            action='store_true',
            help='é‡ç½®ä¸ºé»˜è®¤é…ç½®'
        )
        
        config_group.add_argument(
            '--validate',
            action='store_true',
            help='éªŒè¯é…ç½®æ–‡ä»¶'
        )
        
        # æ‰¹é‡å¤„ç†å‘½ä»¤
        batch_parser = subparsers.add_parser(
            'batch',
            help='æ‰¹é‡å¤„ç†',
            description='æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡ä»¶'
        )
        
        batch_parser.add_argument(
            'filelist',
            help='åŒ…å«æ–‡ä»¶è·¯å¾„åˆ—è¡¨çš„æ–‡æœ¬æ–‡ä»¶'
        )
        
        batch_parser.add_argument(
            '--parallel',
            type=int,
            default=1,
            help='å¹¶è¡Œå¤„ç†æ•°é‡ (é»˜è®¤: 1)'
        )
        
        batch_parser.add_argument(
            '--continue-on-error',
            action='store_true',
            help='é‡åˆ°é”™è¯¯æ—¶ç»§ç»­å¤„ç†å…¶ä»–æ–‡ä»¶'
        )
        
        # ç»Ÿè®¡å‘½ä»¤
        stats_parser = subparsers.add_parser(
            'stats',
            help='ç»Ÿè®¡ä¿¡æ¯',
            description='æ˜¾ç¤ºå¤„ç†ç»Ÿè®¡ä¿¡æ¯'
        )
        
        stats_parser.add_argument(
            'input',
            nargs='?',
            help='è¾“å…¥ç›®å½•æˆ–ç»“æœæ–‡ä»¶'
        )
        
        stats_parser.add_argument(
            '--summary',
            action='store_true',
            help='æ˜¾ç¤ºæ±‡æ€»ç»Ÿè®¡'
        )
        
        # å·¥å…·å‘½ä»¤
        tools_parser = subparsers.add_parser(
            'tools',
            help='å®ç”¨å·¥å…·',
            description='æä¾›å„ç§å®ç”¨å·¥å…·'
        )
        
        tools_subparsers = tools_parser.add_subparsers(dest='tool', help='å¯ç”¨å·¥å…·')
        
        # æ¸…ç†å·¥å…·
        clean_parser = tools_subparsers.add_parser('clean', help='æ¸…ç†ä¸´æ—¶æ–‡ä»¶')
        clean_parser.add_argument('--all', action='store_true', help='æ¸…ç†æ‰€æœ‰æ–‡ä»¶')
        
        # è½¬æ¢å·¥å…·
        convert_parser = tools_subparsers.add_parser('convert', help='æ ¼å¼è½¬æ¢')
        convert_parser.add_argument('input', help='è¾“å…¥æ–‡ä»¶')
        convert_parser.add_argument('--to', choices=['json', 'csv', 'txt'], required=True, help='ç›®æ ‡æ ¼å¼')
        
        return parser
    
    def setup_logging(self, verbose: bool = False, quiet: bool = False):
        """
        è®¾ç½®æ—¥å¿—é…ç½®
        
        Args:
            verbose: è¯¦ç»†æ¨¡å¼
            quiet: é™é»˜æ¨¡å¼
        """
        if quiet:
            level = logging.ERROR
        elif verbose:
            level = logging.DEBUG
        else:
            level = logging.INFO
        
        logging.basicConfig(
            level=level,
            format='%(asctime)s - %(levelname)s - %(message)s',
            datefmt='%H:%M:%S'
        )
    
    def print_progress(self, current: int, total: int, message: str = ""):
        """
        æ‰“å°è¿›åº¦æ¡
        
        Args:
            current: å½“å‰è¿›åº¦
            total: æ€»æ•°
            message: é™„åŠ æ¶ˆæ¯
        """
        if total == 0:
            return
        
        percent = (current / total) * 100
        bar_length = 40
        filled_length = int(bar_length * current // total)
        
        bar = 'â–ˆ' * filled_length + '-' * (bar_length - filled_length)
        
        print(f'\rè¿›åº¦: |{bar}| {percent:.1f}% ({current}/{total}) {message}', end='', flush=True)
        
        if current == total:
            print()  # æ¢è¡Œ
    
    def format_output(self, data: Any, format_type: str = 'text') -> str:
        """
        æ ¼å¼åŒ–è¾“å‡ºæ•°æ®
        
        Args:
            data: è¦æ ¼å¼åŒ–çš„æ•°æ®
            format_type: è¾“å‡ºæ ¼å¼
            
        Returns:
            str: æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
        """
        if format_type == 'json':
            return json.dumps(data, ensure_ascii=False, indent=2, default=str)
        elif format_type == 'csv':
            # ç®€å•çš„CSVæ ¼å¼åŒ–
            if isinstance(data, dict):
                lines = ['key,value']
                for k, v in data.items():
                    lines.append(f'"{k}","{v}"')
                return '\n'.join(lines)
            else:
                return str(data)
        else:
            # æ–‡æœ¬æ ¼å¼
            if isinstance(data, dict):
                lines = []
                for k, v in data.items():
                    if isinstance(v, dict):
                        lines.append(f"{k}:")
                        for sub_k, sub_v in v.items():
                            lines.append(f"  {sub_k}: {sub_v}")
                    else:
                        lines.append(f"{k}: {v}")
                return '\n'.join(lines)
            else:
                return str(data)
    
    def process_command(self, args) -> int:
        """
        å¤„ç†processå‘½ä»¤
        
        Args:
            args: å‘½ä»¤è¡Œå‚æ•°
            
        Returns:
            int: é€€å‡ºç 
        """
        try:
            input_path = Path(args.input)
            
            if not input_path.exists():
                print(f"âŒ é”™è¯¯: æ–‡ä»¶æˆ–ç›®å½•ä¸å­˜åœ¨: {input_path}")
                return 1
            
            # æ›´æ–°é…ç½®
            if args.strategy:
                self.config_manager.set_value('chunking_strategies.default_strategy', args.strategy)
            if args.chunk_size:
                self.config_manager.set_value('chunk_processing.target_chunk_size', args.chunk_size)
            if args.keywords:
                self.config_manager.set_value('keyword_extraction.max_keywords_per_chunk', args.keywords)
            
            # é‡æ–°åˆå§‹åŒ–å¤„ç†å™¨
            self.document_processor = DocumentProcessor(self.config_manager)
            
            files_to_process = []
            
            if input_path.is_file():
                files_to_process.append(input_path)
            elif input_path.is_dir():
                if args.recursive:
                    # é€’å½’æŸ¥æ‰¾æ‰€æœ‰æ”¯æŒçš„æ–‡ä»¶
                    extensions = {'.md', '.markdown', '.txt'}
                    for ext in extensions:
                        files_to_process.extend(input_path.rglob(f'*{ext}'))
                else:
                    # åªå¤„ç†å½“å‰ç›®å½•çš„æ–‡ä»¶
                    extensions = {'.md', '.markdown', '.txt'}
                    for file_path in input_path.iterdir():
                        if file_path.is_file() and file_path.suffix.lower() in extensions:
                            files_to_process.append(file_path)
            
            if not files_to_process:
                print("âŒ é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°å¯å¤„ç†çš„æ–‡ä»¶")
                return 1
            
            print(f"ğŸ“ æ‰¾åˆ° {len(files_to_process)} ä¸ªæ–‡ä»¶å¾…å¤„ç†")
            
            # å¤„ç†æ–‡ä»¶
            results = []
            for i, file_path in enumerate(files_to_process, 1):
                self.print_progress(i-1, len(files_to_process), f"å¤„ç† {file_path.name}")
                
                try:
                    # å¤„ç†æ–‡æ¡£
                    result = self.document_processor.process_file(str(file_path))
                    
                    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶
                    output_base = self.output_dir / f"{file_path.stem}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    
                    # ä¿å­˜åˆ†å—ç»“æœ
                    chunks_file = output_base.with_suffix('.chunks.txt')
                    with open(chunks_file, 'w', encoding='utf-8') as f:
                        for j, chunk in enumerate(result.chunks, 1):
                            f.write(f"=== åˆ†å— {j} ===\n")
                            f.write(f"å¤§å°: {len(chunk.content)} å­—ç¬¦\n")
                            f.write(f"å…³é”®è¯: {', '.join(chunk.keywords)}\n")
                            f.write(f"è´¨é‡è¯„åˆ†: {chunk.quality_score:.2f}\n")
                            f.write(f"å†…å®¹:\n{chunk.content}\n\n")
                    
                    # ä¿å­˜å…³é”®è¯ç»“æœ
                    if args.save_intermediate:
                        keywords_file = output_base.with_suffix('.keywords.json')
                        keywords_data = {
                            'total_keywords': result.total_keywords,
                            'keywords_by_chunk': [
                                {'chunk_id': j+1, 'keywords': chunk.keywords}
                                for j, chunk in enumerate(result.chunks)
                            ],
                            'keyword_frequency': {}  # ProcessingResultæ²¡æœ‰keyword_frequencyå±æ€§
                        }
                        
                        with open(keywords_file, 'w', encoding='utf-8') as f:
                            json.dump(keywords_data, f, ensure_ascii=False, indent=2)
                    
                    # è´¨é‡è¯„ä¼°
                    if not args.no_evaluation:
                        evaluation_result = self.quality_evaluator.evaluate_file(str(file_path))
                        
                        if args.save_intermediate:
                            eval_file = output_base.with_suffix('.evaluation.json')
                            with open(eval_file, 'w', encoding='utf-8') as f:
                                json.dump(asdict(evaluation_result), f, ensure_ascii=False, indent=2, default=str)
                    
                    results.append({
                        'file': str(file_path),
                        'chunks': len(result.chunks),
                        'keywords': result.total_keywords,
                        'processing_time': result.processing_time,
                        'output_file': str(chunks_file)
                    })
                    
                except Exception as e:
                    print(f"\nâŒ å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
                    if not args.continue_on_error:
                        return 1
            
            self.print_progress(len(files_to_process), len(files_to_process), "å®Œæˆ")
            
            # è¾“å‡ºç»“æœæ‘˜è¦
            print(f"\nâœ… å¤„ç†å®Œæˆ!")
            print(f"ğŸ“Š å¤„ç†ç»Ÿè®¡:")
            print(f"  - æ–‡ä»¶æ•°é‡: {len(results)}")
            print(f"  - æ€»åˆ†å—æ•°: {sum(r['chunks'] for r in results)}")
            print(f"  - æ€»å…³é”®è¯æ•°: {sum(r['keywords'] for r in results)}")
            print(f"  - å¹³å‡å¤„ç†æ—¶é—´: {sum(r['processing_time'] for r in results) / len(results):.2f}ç§’")
            
            # è¾“å‡ºè¯¦ç»†ç»“æœ
            if args.format != 'text':
                print(f"\n{self.format_output(results, args.format)}")
            
            return 0
            
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            if args.verbose:
                import traceback
                traceback.print_exc()
            return 1
    
    def evaluate_command(self, args) -> int:
        """
        å¤„ç†evaluateå‘½ä»¤
        
        Args:
            args: å‘½ä»¤è¡Œå‚æ•°
            
        Returns:
            int: é€€å‡ºç 
        """
        try:
            input_path = Path(args.input)
            
            if not input_path.exists():
                print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
                return 1
            
            print(f"ğŸ” è¯„ä¼°æ–‡æ¡£: {input_path}")
            
            # æ‰§è¡Œè¯„ä¼°
            result = self.quality_evaluator.evaluate_file(str(input_path))
            
            # æ˜¾ç¤ºç»“æœ
            print(f"\nğŸ“Š è¯„ä¼°ç»“æœ:")
            print(f"  - æ€»ä½“è¯„åˆ†: {result.overall_score:.2f}")
            print(f"  - è´¨é‡ç­‰çº§: {result.quality_level.value}")
            print(f"  - åˆ†å—æ•°é‡: {len(result.chunk_scores)}")
            print(f"  - å¹³å‡åˆ†å—å¤§å°: {result.avg_chunk_size:.0f} å­—ç¬¦")
            
            if args.detailed:
                print(f"\nğŸ“ˆ è¯¦ç»†æŒ‡æ ‡:")
                for metric, score in result.detailed_metrics.items():
                    print(f"  - {metric}: {score:.2f}")
                
                print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
                for suggestion in result.suggestions:
                    print(f"  â€¢ {suggestion}")
            
            # å¯¼å‡ºç»“æœ
            if args.export:
                export_path = Path(args.export)
                with open(export_path, 'w', encoding='utf-8') as f:
                    json.dump(asdict(result), f, ensure_ascii=False, indent=2, default=str)
                print(f"\nğŸ’¾ ç»“æœå·²å¯¼å‡ºåˆ°: {export_path}")
            
            return 0
            
        except Exception as e:
            print(f"âŒ è¯„ä¼°å¤±è´¥: {e}")
            if args.verbose:
                import traceback
                traceback.print_exc()
            return 1
    
    def config_command(self, args) -> int:
        """
        å¤„ç†configå‘½ä»¤
        
        Args:
            args: å‘½ä»¤è¡Œå‚æ•°
            
        Returns:
            int: é€€å‡ºç 
        """
        try:
            if args.show:
                # æ˜¾ç¤ºå½“å‰é…ç½®
                config = self.config_manager.get_config()
                print("âš™ï¸  å½“å‰é…ç½®:")
                print(self.format_output(config, args.format))
                
            elif args.set:
                # è®¾ç½®é…ç½®é¡¹
                for setting in args.set:
                    if '=' not in setting:
                        print(f"âŒ é”™è¯¯: æ— æ•ˆçš„è®¾ç½®æ ¼å¼: {setting}")
                        return 1
                    
                    key, value = setting.split('=', 1)
                    
                    # å°è¯•è½¬æ¢å€¼ç±»å‹
                    try:
                        if value.lower() in ('true', 'false'):
                            value = value.lower() == 'true'
                        elif value.isdigit():
                            value = int(value)
                        elif '.' in value and value.replace('.', '').isdigit():
                            value = float(value)
                    except ValueError:
                        pass  # ä¿æŒå­—ç¬¦ä¸²ç±»å‹
                    
                    self.config_manager.set_config(key, value)
                    print(f"âœ… è®¾ç½® {key} = {value}")
                
                # ä¿å­˜é…ç½®
                self.config_manager.save_config()
                print("ğŸ’¾ é…ç½®å·²ä¿å­˜")
                
            elif args.reset:
                # é‡ç½®é…ç½®
                self.config_manager.reset_to_default()
                self.config_manager.save_config()
                print("ğŸ”„ é…ç½®å·²é‡ç½®ä¸ºé»˜è®¤å€¼")
                
            elif args.validate:
                # éªŒè¯é…ç½®
                is_valid, errors = self.config_manager.validate_config()
                if is_valid:
                    print("âœ… é…ç½®æ–‡ä»¶æœ‰æ•ˆ")
                else:
                    print("âŒ é…ç½®æ–‡ä»¶æ— æ•ˆ:")
                    for error in errors:
                        print(f"  â€¢ {error}")
                    return 1
            
            return 0
            
        except Exception as e:
            print(f"âŒ é…ç½®æ“ä½œå¤±è´¥: {e}")
            if args.verbose:
                import traceback
                traceback.print_exc()
            return 1
    
    def batch_command(self, args) -> int:
        """
        å¤„ç†batchå‘½ä»¤
        
        Args:
            args: å‘½ä»¤è¡Œå‚æ•°
            
        Returns:
            int: é€€å‡ºç 
        """
        try:
            filelist_path = Path(args.filelist)
            
            if not filelist_path.exists():
                print(f"âŒ é”™è¯¯: æ–‡ä»¶åˆ—è¡¨ä¸å­˜åœ¨: {filelist_path}")
                return 1
            
            # è¯»å–æ–‡ä»¶åˆ—è¡¨
            with open(filelist_path, 'r', encoding='utf-8') as f:
                file_paths = [line.strip() for line in f if line.strip()]
            
            # éªŒè¯æ–‡ä»¶å­˜åœ¨æ€§
            valid_files = []
            for file_path in file_paths:
                path = Path(file_path)
                if path.exists():
                    valid_files.append(path)
                else:
                    print(f"âš ï¸  è­¦å‘Š: æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            
            if not valid_files:
                print("âŒ é”™è¯¯: æ²¡æœ‰æœ‰æ•ˆçš„æ–‡ä»¶å¯å¤„ç†")
                return 1
            
            print(f"ğŸ“ æ‰¹é‡å¤„ç† {len(valid_files)} ä¸ªæ–‡ä»¶")
            
            # å¤„ç†æ–‡ä»¶
            success_count = 0
            error_count = 0
            
            for i, file_path in enumerate(valid_files, 1):
                self.print_progress(i-1, len(valid_files), f"å¤„ç† {file_path.name}")
                
                try:
                    # å¤„ç†æ–‡æ¡£
                    result = self.document_processor.process_file(str(file_path))
                    
                    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶
                    output_file = self.output_dir / f"{file_path.stem}_batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}.chunks.txt"
                    
                    with open(output_file, 'w', encoding='utf-8') as f:
                        for j, chunk in enumerate(result.chunks, 1):
                            f.write(f"=== åˆ†å— {j} ===\n")
                            f.write(f"å¤§å°: {len(chunk.content)} å­—ç¬¦\n")
                            f.write(f"å…³é”®è¯: {', '.join(chunk.keywords)}\n")
                            f.write(f"è´¨é‡è¯„åˆ†: {chunk.quality_score:.2f}\n")
                            f.write(f"å†…å®¹:\n{chunk.content}\n\n")
                    
                    success_count += 1
                    
                except Exception as e:
                    error_count += 1
                    if not args.continue_on_error:
                        print(f"\nâŒ å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
                        return 1
            
            self.print_progress(len(valid_files), len(valid_files), "å®Œæˆ")
            
            print(f"\nâœ… æ‰¹é‡å¤„ç†å®Œæˆ!")
            print(f"ğŸ“Š å¤„ç†ç»Ÿè®¡:")
            print(f"  - æˆåŠŸ: {success_count}")
            print(f"  - å¤±è´¥: {error_count}")
            print(f"  - æ€»è®¡: {len(valid_files)}")
            
            return 0 if error_count == 0 else 1
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {e}")
            if args.verbose:
                import traceback
                traceback.print_exc()
            return 1
    
    def stats_command(self, args) -> int:
        """
        å¤„ç†statså‘½ä»¤
        
        Args:
            args: å‘½ä»¤è¡Œå‚æ•°
            
        Returns:
            int: é€€å‡ºç 
        """
        try:
            if args.input:
                input_path = Path(args.input)
                if not input_path.exists():
                    print(f"âŒ é”™è¯¯: è·¯å¾„ä¸å­˜åœ¨: {input_path}")
                    return 1
            else:
                input_path = self.output_dir
            
            # ç»Ÿè®¡è¾“å‡ºæ–‡ä»¶
            chunk_files = list(input_path.glob('*.chunks.txt'))
            keyword_files = list(input_path.glob('*.keywords.json'))
            eval_files = list(input_path.glob('*.evaluation.json'))
            
            print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ ({input_path}):")
            print(f"  - åˆ†å—æ–‡ä»¶: {len(chunk_files)}")
            print(f"  - å…³é”®è¯æ–‡ä»¶: {len(keyword_files)}")
            print(f"  - è¯„ä¼°æ–‡ä»¶: {len(eval_files)}")
            
            if args.summary and chunk_files:
                # è¯¦ç»†ç»Ÿè®¡
                total_chunks = 0
                total_size = 0
                
                for chunk_file in chunk_files:
                    try:
                        with open(chunk_file, 'r', encoding='utf-8') as f:
                            content = f.read()
                            chunks = content.count('=== åˆ†å—')
                            total_chunks += chunks
                            total_size += len(content)
                    except Exception:
                        continue
                
                print(f"\nğŸ“ˆ è¯¦ç»†ç»Ÿè®¡:")
                print(f"  - æ€»åˆ†å—æ•°: {total_chunks}")
                print(f"  - å¹³å‡æ¯æ–‡ä»¶åˆ†å—æ•°: {total_chunks / len(chunk_files):.1f}")
                print(f"  - æ€»æ–‡ä»¶å¤§å°: {total_size / 1024:.1f} KB")
                print(f"  - å¹³å‡æ–‡ä»¶å¤§å°: {total_size / len(chunk_files) / 1024:.1f} KB")
            
            return 0
            
        except Exception as e:
            print(f"âŒ ç»Ÿè®¡å¤±è´¥: {e}")
            if args.verbose:
                import traceback
                traceback.print_exc()
            return 1
    
    def tools_command(self, args) -> int:
        """
        å¤„ç†toolså‘½ä»¤
        
        Args:
            args: å‘½ä»¤è¡Œå‚æ•°
            
        Returns:
            int: é€€å‡ºç 
        """
        try:
            if args.tool == 'clean':
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if args.all:
                    # æ¸…ç†æ‰€æœ‰è¾“å‡ºæ–‡ä»¶
                    files_to_clean = list(self.output_dir.glob('*'))
                else:
                    # åªæ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    files_to_clean = list(self.output_dir.glob('*.tmp'))
                    files_to_clean.extend(self.output_dir.glob('*.temp'))
                
                if not files_to_clean:
                    print("âœ… æ²¡æœ‰éœ€è¦æ¸…ç†çš„æ–‡ä»¶")
                    return 0
                
                print(f"ğŸ§¹ æ¸…ç† {len(files_to_clean)} ä¸ªæ–‡ä»¶...")
                
                for file_path in files_to_clean:
                    try:
                        if file_path.is_file():
                            file_path.unlink()
                        elif file_path.is_dir():
                            import shutil
                            shutil.rmtree(file_path)
                    except Exception as e:
                        print(f"âš ï¸  æ— æ³•åˆ é™¤ {file_path}: {e}")
                
                print("âœ… æ¸…ç†å®Œæˆ")
                
            elif args.tool == 'convert':
                # æ ¼å¼è½¬æ¢
                input_path = Path(args.input)
                if not input_path.exists():
                    print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
                    return 1
                
                output_path = input_path.with_suffix(f'.{args.to}')
                
                # è¯»å–è¾“å…¥æ–‡ä»¶
                with open(input_path, 'r', encoding='utf-8') as f:
                    if input_path.suffix == '.json':
                        data = json.load(f)
                    else:
                        data = f.read()
                
                # è½¬æ¢å¹¶ä¿å­˜
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write(self.format_output(data, args.to))
                
                print(f"âœ… è½¬æ¢å®Œæˆ: {output_path}")
            
            return 0
            
        except Exception as e:
            print(f"âŒ å·¥å…·æ“ä½œå¤±è´¥: {e}")
            if args.verbose:
                import traceback
                traceback.print_exc()
            return 1
    
    def run(self, argv: Optional[List[str]] = None) -> int:
        """
        è¿è¡Œå‘½ä»¤è¡Œç•Œé¢
        
        Args:
            argv: å‘½ä»¤è¡Œå‚æ•°åˆ—è¡¨
            
        Returns:
            int: é€€å‡ºç 
        """
        parser = self.create_parser()
        args = parser.parse_args(argv)
        
        # è®¾ç½®æ—¥å¿—
        self.setup_logging(args.verbose, args.quiet)
        
        # æ›´æ–°é…ç½®è·¯å¾„
        if args.config != 'config.json':
            self.config_path = args.config
            self.config_manager = ConfigManager(self.config_path)
            self.document_processor = DocumentProcessor(self.config_manager)
            self.quality_evaluator = QualityEvaluator(self.config_manager.config)
        
        # æ›´æ–°è¾“å‡ºç›®å½•
        if args.output != 'outputs':
            self.output_dir = Path(args.output)
            self.output_dir.mkdir(exist_ok=True)
        
        # æ‰§è¡Œå‘½ä»¤
        if args.command == 'process':
            return self.process_command(args)
        elif args.command == 'evaluate':
            return self.evaluate_command(args)
        elif args.command == 'config':
            return self.config_command(args)
        elif args.command == 'batch':
            return self.batch_command(args)
        elif args.command == 'stats':
            return self.stats_command(args)
        elif args.command == 'tools':
            return self.tools_command(args)
        else:
            parser.print_help()
            return 0


def main():
    """
    ä¸»å‡½æ•°ï¼Œç”¨äºè¿è¡Œå‘½ä»¤è¡Œç•Œé¢
    """
    try:
        cli = CLIInterface()
        exit_code = cli.run()
        sys.exit(exit_code)
        
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æ“ä½œå·²å–æ¶ˆ")
        sys.exit(130)
    except Exception as e:
        print(f"âŒ ç¨‹åºå¼‚å¸¸: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()