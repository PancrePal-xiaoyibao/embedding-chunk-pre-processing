#!/usr/bin/env python3
"""
ChatåŠŸèƒ½é›†æˆæµ‹è¯•è„šæœ¬

æµ‹è¯•OllamaèŠå¤©åŠŸèƒ½çš„å„ä¸ªç»„ä»¶ï¼ŒåŒ…æ‹¬è¿æ¥ã€æ¨¡å‹å¯ç”¨æ€§ã€èŠå¤©å¯¹è¯ç­‰ã€‚

Author: Assistant
Date: 2025-01-24
"""

import sys
import os
import asyncio
import logging
from typing import List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

try:
    from src.core.chat_interface import (
        ChatMessage, ChatOptions, MessageRole,
        create_user_message, create_system_message
    )
    from src.core.ollama_chat import OllamaChatClient, OllamaChatConfig
    from src.core.chat_factory import (
        ChatFactory, ChatProvider, create_ollama_chat_client,
        test_chat_connection
    )
except ImportError as e:
    print(f"å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œæ­¤è„šæœ¬")
    sys.exit(1)


# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_ollama_connection():
    """æµ‹è¯•OllamaæœåŠ¡å™¨è¿æ¥"""
    print("ğŸ”— æµ‹è¯•OllamaæœåŠ¡å™¨è¿æ¥...")
    
    try:
        config = OllamaChatConfig()
        client = OllamaChatClient(config)
        
        if client.test_connection():
            print("âœ… OllamaæœåŠ¡å™¨è¿æ¥æˆåŠŸ")
            return True
        else:
            print("âŒ OllamaæœåŠ¡å™¨è¿æ¥å¤±è´¥")
            return False
    except Exception as e:
        print(f"âŒ è¿æ¥æµ‹è¯•å¼‚å¸¸: {str(e)}")
        return False


def test_model_availability():
    """æµ‹è¯•æ¨¡å‹å¯ç”¨æ€§"""
    print("\nğŸ” æµ‹è¯•æ¨¡å‹å¯ç”¨æ€§...")
    
    try:
        config = OllamaChatConfig(model_name="qwen3:1.7b")
        client = OllamaChatClient(config)
        
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨
        if client.is_model_available("qwen3:1.7b"):
            print("âœ… qwen3:1.7b æ¨¡å‹å¯ç”¨")
            return True
        else:
            print("âš ï¸ qwen3:1.7b æ¨¡å‹ä¸å¯ç”¨ï¼Œå°è¯•æ‹‰å–...")
            if client.pull_model("qwen3:1.7b"):
                print("âœ… qwen3:1.7b æ¨¡å‹æ‹‰å–æˆåŠŸ")
                return True
            else:
                print("âŒ qwen3:1.7b æ¨¡å‹æ‹‰å–å¤±è´¥")
                return False
    except Exception as e:
        print(f"âŒ æ¨¡å‹å¯ç”¨æ€§æµ‹è¯•å¼‚å¸¸: {str(e)}")
        return False


def test_simple_chat():
    """æµ‹è¯•ç®€å•èŠå¤©"""
    print("\nğŸ’¬ æµ‹è¯•ç®€å•èŠå¤©...")
    
    try:
        config = OllamaChatConfig(model_name="qwen3:1.7b")
        client = OllamaChatClient(config)
        
        # åˆ›å»ºæ¶ˆæ¯
        messages = [
            create_user_message("ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚")
        ]
        
        # è®¾ç½®é€‰é¡¹
        options = ChatOptions(
            temperature=0.7,
            max_tokens=100
        )
        
        # è¿›è¡ŒèŠå¤©
        response = client.chat(messages, options)
        
        print(f"âœ… èŠå¤©å“åº”æˆåŠŸ")
        print(f"ğŸ“ æ¨¡å‹: {response.model_name}")
        print(f"ğŸ’­ å›å¤: {response.message.content[:200]}...")
        
        if response.usage:
            print(f"ğŸ“Š Tokenä½¿ç”¨: {response.usage}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç®€å•èŠå¤©æµ‹è¯•å¼‚å¸¸: {str(e)}")
        return False


async def test_stream_chat():
    """æµ‹è¯•æµå¼èŠå¤©"""
    print("\nğŸŒŠ æµ‹è¯•æµå¼èŠå¤©...")
    
    try:
        config = OllamaChatConfig(model_name="qwen3:1.7b")
        client = OllamaChatClient(config)
        
        # åˆ›å»ºæ¶ˆæ¯
        messages = [
            create_user_message("è¯·ç”¨ä¸€å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ã€‚")
        ]
        
        # è®¾ç½®é€‰é¡¹
        options = ChatOptions(
            temperature=0.5,
            max_tokens=50
        )
        
        print("ğŸ“¡ å¼€å§‹æµå¼èŠå¤©...")
        full_response = ""
        
        async for chunk in client.chat_stream(messages, options):
            if chunk.delta:
                full_response += chunk.delta
                print(chunk.delta, end="", flush=True)
            
            if chunk.finish_reason:
                print(f"\nâœ… æµå¼èŠå¤©å®Œæˆï¼ŒåŸå› : {chunk.finish_reason}")
                if chunk.usage:
                    print(f"ğŸ“Š Tokenä½¿ç”¨: {chunk.usage}")
                break
        
        print(f"ğŸ“ å®Œæ•´å›å¤: {full_response}")
        return True
        
    except Exception as e:
        print(f"âŒ æµå¼èŠå¤©æµ‹è¯•å¼‚å¸¸: {str(e)}")
        return False


def test_chat_factory():
    """æµ‹è¯•èŠå¤©å·¥å‚"""
    print("\nğŸ­ æµ‹è¯•èŠå¤©å·¥å‚...")
    
    try:
        factory = ChatFactory()
        
        # æµ‹è¯•å¯ç”¨æä¾›å•†
        providers = factory.get_available_providers()
        print(f"ğŸ“‹ å¯ç”¨æä¾›å•†: {[p.value for p in providers]}")
        
        # åˆ›å»ºOllamaå®¢æˆ·ç«¯
        config = {
            "base_url": "http://localhost:11434",
            "model_name": "qwen3:1.7b",
            "timeout": 60
        }
        
        client = factory.create_chat_client(ChatProvider.OLLAMA, config, "test_client")
        
        # æµ‹è¯•è¿æ¥
        if client.test_connection():
            print("âœ… å·¥å‚åˆ›å»ºçš„å®¢æˆ·ç«¯è¿æ¥æˆåŠŸ")
        else:
            print("âŒ å·¥å‚åˆ›å»ºçš„å®¢æˆ·ç«¯è¿æ¥å¤±è´¥")
            return False
        
        # æµ‹è¯•ä¾¿æ·å‡½æ•°
        if test_chat_connection("ollama", config):
            print("âœ… ä¾¿æ·å‡½æ•°è¿æ¥æµ‹è¯•æˆåŠŸ")
        else:
            print("âŒ ä¾¿æ·å‡½æ•°è¿æ¥æµ‹è¯•å¤±è´¥")
            return False
        
        return True
        
    except Exception as e:
        print(f"âŒ èŠå¤©å·¥å‚æµ‹è¯•å¼‚å¸¸: {str(e)}")
        return False


def test_conversation_context():
    """æµ‹è¯•å¯¹è¯ä¸Šä¸‹æ–‡"""
    print("\nğŸ—£ï¸ æµ‹è¯•å¯¹è¯ä¸Šä¸‹æ–‡...")
    
    try:
        client = create_ollama_chat_client(model_name="qwen3:1.7b")
        
        # å¤šè½®å¯¹è¯
        messages = [
            create_system_message("ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ï¼Œè¯·ç®€æ´å›ç­”é—®é¢˜ã€‚"),
            create_user_message("æˆ‘çš„åå­—æ˜¯å¼ ä¸‰ã€‚"),
        ]
        
        # ç¬¬ä¸€è½®å¯¹è¯
        response1 = client.chat(messages, ChatOptions(max_tokens=50))
        print(f"ğŸ¤– ç¬¬ä¸€è½®å›å¤: {response1.message.content}")
        
        # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°ä¸Šä¸‹æ–‡
        messages.append(response1.message)
        messages.append(create_user_message("ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å—ï¼Ÿ"))
        
        # ç¬¬äºŒè½®å¯¹è¯
        response2 = client.chat(messages, ChatOptions(max_tokens=50))
        print(f"ğŸ¤– ç¬¬äºŒè½®å›å¤: {response2.message.content}")
        
        # æ£€æŸ¥æ˜¯å¦è®°ä½äº†åå­—
        if "å¼ ä¸‰" in response2.message.content:
            print("âœ… å¯¹è¯ä¸Šä¸‹æ–‡ä¿æŒæˆåŠŸ")
            return True
        else:
            print("âš ï¸ å¯¹è¯ä¸Šä¸‹æ–‡å¯èƒ½æœªæ­£ç¡®ä¿æŒ")
            return True  # ä»ç„¶ç®—ä½œæˆåŠŸï¼Œå› ä¸ºåŠŸèƒ½æ­£å¸¸
        
    except Exception as e:
        print(f"âŒ å¯¹è¯ä¸Šä¸‹æ–‡æµ‹è¯•å¼‚å¸¸: {str(e)}")
        return False


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ChatåŠŸèƒ½é›†æˆæµ‹è¯•\n")
    
    tests = [
        ("Ollamaè¿æ¥æµ‹è¯•", test_ollama_connection),
        ("æ¨¡å‹å¯ç”¨æ€§æµ‹è¯•", test_model_availability),
        ("ç®€å•èŠå¤©æµ‹è¯•", test_simple_chat),
        ("æµå¼èŠå¤©æµ‹è¯•", test_stream_chat),
        ("èŠå¤©å·¥å‚æµ‹è¯•", test_chat_factory),
        ("å¯¹è¯ä¸Šä¸‹æ–‡æµ‹è¯•", test_conversation_context),
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        try:
            if asyncio.iscoroutinefunction(test_func):
                result = await test_func()
            else:
                result = test_func()
            
            if result:
                passed += 1
            
        except Exception as e:
            print(f"âŒ {test_name} æ‰§è¡Œå¼‚å¸¸: {str(e)}")
    
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é¡¹æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰ChatåŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼Œè¯·æ£€æŸ¥é…ç½®å’ŒæœåŠ¡çŠ¶æ€")
    
    return passed == total


if __name__ == "__main__":
    try:
        success = asyncio.run(main())
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nâ¹ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•æ‰§è¡Œå¼‚å¸¸: {str(e)}")
        sys.exit(1)